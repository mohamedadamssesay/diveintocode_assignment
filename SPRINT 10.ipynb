{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sprint9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uECBDtFUbm_Q"
      },
      "source": [
        "# importing dependencies\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We0Ryhlqbm_g"
      },
      "source": [
        "# get subsets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiNoksA-bm_h",
        "outputId": "a6bd85e3-4d50-444f-9455-0086941ec750"
      },
      "source": [
        "# checking the subsets\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rNkkIbjbm_k"
      },
      "source": [
        "# flattening the subsets\n",
        "X_train = X_train.reshape(-1,784)\n",
        "X_test = X_test.reshape(-1,784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "da7azwaVbm_l",
        "outputId": "116a0f00-70b9-471b-cc83-cc58b396df6d"
      },
      "source": [
        "# visualize the data\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9giwg0Xbm_m",
        "outputId": "1a04adba-fe0e-4dfd-ecb5-2491c41e3ece"
      },
      "source": [
        "# pre processing\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WcVgBiXbm_o"
      },
      "source": [
        "# splitting our subsets into train and validation subsets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f10EJYL4bm_n",
        "outputId": "85df8b8a-05ed-49fb-e3b5-bf4e0036270b"
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000,)\n",
            "(48000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba1V1yKbm_q",
        "outputId": "1470d405-edfe-4a66-8771-d96ea98ab881"
      },
      "source": [
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZEwNFpbbm_r"
      },
      "source": [
        "# mini batch\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCkrElU3bm_t"
      },
      "source": [
        "# calculating the batch\n",
        "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8vYbTrlbm_u",
        "outputId": "613c31b4-a23b-42ee-d14e-c44ba99eb89c"
      },
      "source": [
        "print(len(get_mini_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO6dTy91bm_u"
      },
      "source": [
        "[Problem 1] Creating a code to determine the initial weight value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZqgUzevbm_v"
      },
      "source": [
        "n_sample,n_features = X_train.shape\n",
        "n_nodes1 = 400\n",
        "sigma = 0.01 # Standard deviation of Gaussian distribution\n",
        "W1 = sigma * np.random.randn(n_features, n_nodes1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4QvA4-Lbm_w",
        "outputId": "ba448345-8b5a-41e1-93e1-1b936d465c9c"
      },
      "source": [
        "print(n_nodes1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuznxApDbm_w"
      },
      "source": [
        "# neural network from scratch\n",
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose = True, n_features=784,n_nodes1=400,n_nodes2=200, batch_size=20,n_output=10, n_epoch=10, lr=0.01, sigma=0.02):\n",
        "        self.verbose = verbose\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.batch_size = batch_size\n",
        "        self.n_output = n_output\n",
        "        self.n_epoch = 30\n",
        "        self.lr = lr\n",
        "        self.sigma = sigma\n",
        "        self.W1 = None\n",
        "        self.b1 = None\n",
        "        self.W2 = None\n",
        "        self.b2 = None\n",
        "        self.W3 = None\n",
        "        self.b3 = None\n",
        "        self.loss = []\n",
        "        self.val_loss = []\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "      self.create_init_w_b()\n",
        "      for epoch in range(self.n_epoch):\n",
        "          get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
        "          for mini_X_train, mini_y_train in get_mini_batch: \n",
        "            # forward propagation\n",
        "            self.forward_propagation(mini_X_train)\n",
        "            self.back_propagation(mini_X_train, mini_y_train)\n",
        "          self.forward_propagation(X)\n",
        "          self.loss.append(self.cross_entropy_error(y, self.layer_3))\n",
        "          if X_val is not None:\n",
        "              self.forward_propagation(X_val)\n",
        "              self.val_loss.append(self.cross_entropy_error(y_val, self.layer_3))\n",
        "\n",
        "      if self.verbose:\n",
        "          # When verbose is set to True, the learning process etc. is output.\n",
        "          print(self.loss)\n",
        "      pass\n",
        "    \n",
        "    def create_init_w_b(self):\n",
        "      self.W1 = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
        "      self.b1 = self.sigma * np.random.randn(1, self.n_nodes1)\n",
        "      self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
        "      self.b2 = self.sigma * np.random.randn(1, self.n_nodes2)\n",
        "      self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
        "      self.b3 = self.sigma * np.random.randn(1, self.n_output)\n",
        "    \n",
        "    def activation_function(self,X, layer):\n",
        "      if layer == \"hidden\" or layer == \"first\":\n",
        "        act_f = np.tanh(X)\n",
        "        return act_f\n",
        "      else: \n",
        "        act_f = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)\n",
        "        return act_f\n",
        "\n",
        "    def cross_entropy_error(self, y, Z):\n",
        "      return -np.sum([y[i]*np.log2(Z[i]) for i in range(len(y))])\n",
        "\n",
        "    def forward_propagation(self,X):\n",
        "        self.layer_1_pre = np.matmul(X,self.W1) + self.b1\n",
        "        self.layer_1 = self.activation_function(self.layer_1_pre, \"first\")\n",
        "\n",
        "        self.layer_2_pre = np.matmul(self.layer_1,self.W2) + self.b2\n",
        "        self.layer_2 = self.activation_function(self.layer_2_pre, \"hidden\")\n",
        "\n",
        "        self.layer_3_pre = np.matmul(self.layer_2,self.W3) + self.b3\n",
        "        self.layer_3 = self.activation_function(self.layer_3_pre, \"output\")\n",
        "        \n",
        "    def back_propagation(self, X, y):\n",
        "      dA3 = self.layer_3 - y\n",
        "      dB3 = np.sum(dA3, axis=0)\n",
        "      dW3 = self.layer_2.T @ dA3\n",
        "      dZ2 = dA3 @ self.W3.T\n",
        "      dA2 = dZ2 * (1 - self.activation_function(self.layer_2_pre, \"hidden\")**2)\n",
        "      dB2 = np.sum(dA2, axis=0)\n",
        "      dW2 = self.layer_1.T @ dA2\n",
        "      dZ1 = dA2 @ self.W2.T\n",
        "      dA1 = dZ1 * (1 - self.activation_function(self.layer_1_pre, \"first\")**2)\n",
        "      dB1 = np.sum(dA1, axis=0)\n",
        "      dW1 = X.T @ dA1\n",
        "      self.W3 -= self.lr * dW3\n",
        "      self.b3 -= self.lr * dB3\n",
        "      self.W2 -= self.lr * dW2\n",
        "      self.b2 -= self.lr * dB2\n",
        "      self.W1 -= self.lr * dW1\n",
        "      self.b1 -= self.lr * dB1\n",
        "\n",
        "    def predict(self, X):\n",
        "      self.forward_propagation(X)\n",
        "      return np.argmax(self.layer_3, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA7Fk8NKPQaF"
      },
      "source": [
        "### [Problem 1] Classifying fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnp59gOPF_u"
      },
      "source": [
        "class FC:\r\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation_function):\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.n_nodes1 = n_nodes1\r\n",
        "        self.n_nodes2 = n_nodes2\r\n",
        "        self.af = activation_function\r\n",
        "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\r\n",
        "        self.B = self.initializer.B(self.n_nodes1)\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def forward(self, X): \r\n",
        "      self.layer_pre = np.matmul(X,self.W) + self.b\r\n",
        "      self.layer = self.activation_function(self.layer_pre)\r\n",
        "      return self.layer\r\n",
        "\r\n",
        "    def backward(self, dA):\r\n",
        "      self.dB = np.sum(dA, axis=0)\r\n",
        "      self.dW = self.layer.T @ dA\r\n",
        "      dZ = dA @ self.W.T\r\n",
        "      # update\r\n",
        "      self = self.optimizer.update(self)\r\n",
        "      return dZ"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-7GS0p1T7b8"
      },
      "source": [
        "### [Problem 2] Classifying the initialization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HieiXGUCUBEU"
      },
      "source": [
        "class SimpleInitializer:\r\n",
        "    def __init__(self, sigma):\r\n",
        "        self.sigma = sigma\r\n",
        "    def W(self, n_nodes1, n_nodes2):\r\n",
        "      W = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\r\n",
        "      return W\r\n",
        "    def B(self, n_nodes2):\r\n",
        "      b = self.sigma * np.random.randn(1, self.n_nodes2)\r\n",
        "      return b"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxSr8pRXU1zv"
      },
      "source": [
        "### [Problem 3] Classifying optimization methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbLSDNfU34t"
      },
      "source": [
        "class SGD:\r\n",
        "    def __init__(self, lr):\r\n",
        "        self.lr = lr\r\n",
        "    def update(self, layer):\r\n",
        "      self.W -= self.lr * layer.dW\r\n",
        "      self.b -= self.lr * layer.db"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfE7sr6OV8BY"
      },
      "source": [
        "### [Problem 4] Classifying activation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqf1NZxV-BA"
      },
      "source": [
        "class Sigmoid:\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def calc(X):\r\n",
        "    return 1/(1+np.exp(-X))\r\n",
        "\r\n",
        "class Tanh:\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def calc(X):\r\n",
        "    return np.tanh(X)\r\n",
        "\r\n",
        "class Softmax:\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def calc(X):\r\n",
        "    return np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxFvsvB2Yi7w"
      },
      "source": [
        "### [Problem 5] ReLU class creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDmGZ1qdYk5L"
      },
      "source": [
        "class ReLu:\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def calc(X):\r\n",
        "    return np.where(X>0,X,0)"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}