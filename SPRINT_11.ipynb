{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint 11 - SimpleConv1d-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pvggFqnGKB2"
      },
      "source": [
        "Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "405Ye1B6GgOc"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.sparse as sp\n",
        "import statsmodels.api as sm\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "from sklearn.metrics import mean_squared_error\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rExUTExKGvkz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def smooth_curve(x):\n",
        "    \"\"\"\n",
        "     Used to smooth the graph of a loss function\n",
        "    Reference: http://glowingpython.blogspot.jp/2012/02/convolution-with-numpy.html\n",
        "    \"\"\"\n",
        "    window_len = 11\n",
        "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
        "    w = np.kaiser(window_len, 2)\n",
        "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
        "    return y[5:len(y)-5]\n",
        "\n",
        "\n",
        "def shuffle_dataset(x, t):\n",
        "    \"\"\"\n",
        "    Perform a shuffle of the dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : training data\n",
        "    t : Teacher data\n",
        "    Returns\n",
        "    -------\n",
        "    x, t : shuffled training and teacher data\n",
        "    \"\"\"\n",
        "    permutation = np.random.permutation(x.shape[0])\n",
        "    x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:]\n",
        "    t = t[permutation]\n",
        "\n",
        "    return x, t\n",
        "\n",
        "def conv_output_size(input_size, filter_size, stride=1, pad=0):\n",
        "    return (input_size + 2*pad - filter_size) / stride + 1\n",
        "\n",
        "\n",
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_data : input data consisting of a 4D array of (number of data, channel, height, width)\n",
        "    filter_h : height of the filter\n",
        "    filter_w : width of the filter\n",
        "    stride : stride\n",
        "    pad : padding\n",
        "    Returns\n",
        "    -------\n",
        "    col : 2D array\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col\n",
        "\n",
        "\n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    col :\n",
        "    input_shape : Shape of input data (example)：(10, 1, 28, 28)）\n",
        "    filter_h :\n",
        "    filter_w\n",
        "    stride\n",
        "    pad\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE7n5VJ_HZ7R"
      },
      "source": [
        "###One-dimensional convolutional neural network scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wD-HfFWG6cQ"
      },
      "source": [
        "We will build a class of convolutional neural networks (CNNs) from scratch, and implement the algorithms using only minimal libraries such as NumPy.\n",
        "\n",
        "In this Sprint, we will build a 1D convolutional layer to understand the basics of convolution. In the next sprint, we will create a 2d convolutional layer and a pooling layer to complete a CNN that is commonly used for images.\n",
        "\n",
        "The name of the class should be Scratch1dCNNClassifier. For the structure of the class, please refer to the ScratchDeepNeuralNetrowkClassifier created in the previous Sprint.\n",
        "\n",
        "What is 1D convolution layer?\n",
        "In CNNs, 2-D convolutional layers for images are standard, but for the sake of understanding, we will implement 1-D convolutional layers first. 1-D convolution is often used in practical applications for series data such as natural language or waveform data.\n",
        "\n",
        "Convolution can be considered for any dimension, and up to 3D convolution for 3D data is commonly available in frameworks.\n",
        "\n",
        "Preparing the dataset\n",
        "For the validation we will continue to use the MNIST dataset, which for 1D convolution is a smoothed input as well as an all-connected neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6pH0yQPHm5s"
      },
      "source": [
        "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#print(X_train.shape) # (60000, 28, 28)\n",
        "#print(X_test.shape) # (10000, 28, 28)\n",
        "#print(X_train[0].dtype) # uint8\n",
        "#print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EGrV4WhH3zG"
      },
      "source": [
        "First of all, make some test data.\n",
        "1dCNN is often used for time series analysis. For this reason, let's make a simple anomaly detection model as test data.\n",
        "\n",
        "Since time series anomaly detection systems are often sequential in nature, it is not really necessary to look at every batch like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gq8NYENzIB5H",
        "outputId": "b847a210-41b4-472d-dfa8-266b5b5a5316"
      },
      "source": [
        "data_length = 100\n",
        "n_sample = 100000\n",
        "anomaly_noise = np.random.randn(data_length)    #Outliers have a high variance\n",
        "nomaly_noise  = np.random.randn(data_length)/2  #Normal values have low variance\n",
        "\n",
        "#generate time series and labels\n",
        "t = np.linspace(0,10,data_length)\n",
        "x_anomaly = np.array([np.sin(t) + anomaly_noise for i in range(n_sample//2)])\n",
        "x_nomaly  = np.array([np.sin(t) + nomaly_noise  for i in range(n_sample//2)])\n",
        "X = np.concatenate([x_anomaly,x_nomaly])\n",
        "y = np.concatenate([np.ones(n_sample//2),np.zeros(n_sample//2)])\n",
        "\n",
        "#Shuffle\n",
        "rand_idx = np.arange(n_sample)\n",
        "np.random.shuffle(rand_idx)\n",
        "X = X[rand_idx,:]\n",
        "y = y[rand_idx]\n",
        "\n",
        "#Drawing\n",
        "plt.plot(t,x_anomaly[0,:])\n",
        "plt.plot(t,x_nomaly[0,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKv1B1RVIX9H"
      },
      "source": [
        "# [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grPz1WucIhdP"
      },
      "source": [
        "class CNN_1d_:\n",
        "    def __init__(self, p=0, s=1):\n",
        "        self.padding = p\n",
        "        self.stride = s\n",
        "    \n",
        "    def forward(self, X, filter_size):\n",
        "        self.X = X\n",
        "        self.input_size = len(X)\n",
        "        self.filter_size = filter_size\n",
        "        self.W = np.random.randint(-2,2,3) \n",
        "        self.B = np.array([1])\n",
        "        # If the input is two-dimensional, calculate HW respectively\n",
        "        self.output_size = ((self.input_size + self.p*2 - self.filter_size) / self.stride) + 1\n",
        "        \n",
        "        \n",
        "    \n",
        "    def backward(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEheY1DIj4E",
        "outputId": "70b85690-deb1-4fa2-989e-d5e2298302ae"
      },
      "source": [
        "XX = np.random.randint(0, 10, 10)\n",
        "ww = np.random.randint(-2,2, 3)\n",
        "print(XX)\n",
        "print(ww)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 8 2 4 2 6 9 1 7 3]\n",
            "[ 0 -1 -2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wixd5EwInv5"
      },
      "source": [
        "# [Problem 2] Output size calculation after one-dimensional convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duw9-9iwIsit"
      },
      "source": [
        "def calc_out_shape(Nin, F, P=0, S=1):\n",
        "    out = ((Nin + 2*P - F) / S ) + 1\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FdGNv24IvHS",
        "outputId": "cfb9ea3b-c040-4678-e1aa-e339cae1f1ec"
      },
      "source": [
        "calc_out_shape(100, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn7U75pcIzqT"
      },
      "source": [
        "# [Problem 3] Experiment of one-dimensional convolutional layer with small array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_-M6O4QJKYg"
      },
      "source": [
        "Check that the forward and back propagation is correct with the small array shown below.\n",
        "\n",
        "Let the input x, the weight w and the bias b be as follows\n",
        "\n",
        "x = np.array([1,2,3,4])\\\n",
        "w = np.array([3, 5, 7])\\\n",
        "b = np.array([1])\\\n",
        "With forward propagation, the output looks like this\n",
        "\n",
        "a = np.array([35, 50])\\\n",
        "Now consider backpropagation. Suppose the error is as follows\n",
        "\n",
        "delta_a = np.array([10, 20])\\\n",
        "If we backpropagate, we get the following value\n",
        "\n",
        "delta_b = np.array([30])\\\n",
        "delta_w = np.array([50, 80, 110])\\\n",
        "delta_x = np.array([30, 110, 170, 140])\\\n",
        "\n",
        "Implementation considerations\\\n",
        "To implement convolution, you can start with a series of for statements. However, we want to make the computation as efficient as possible, so we will consider a way to compute the following expression at once.\n",
        "\n",
        "$$ a_i=\\Sigma^{F-1}_{s=0}x_{(i+s)}w_s+b $$\n",
        "The bias term is a simple addition, so we look at the weights part.\n",
        "\n",
        "$$ \\Sigma^{F-1}_{s=0}x_{(i+s)}w_s $$\n",
        "This is the inner product of an array of w with a part of x taken out of it. Given a concrete situation, we can calculate it with the following code. In this example, to make the flow easier to understand, the adamant product is calculated between each element, and then the sum is calculated. This results in the same as the inner product.\n",
        "\n",
        "x = np.array([1, 2, 3, 4])\\\n",
        "w = np.array([3, 5, 7])\\\n",
        "a = np.empty((2, 3))\\\n",
        "indexes0 = np.array([0, 1, 2]).astype(np.int)\\\n",
        "indexes1 = np.array([1, 2, 3]).astype(np.int)\\\n",
        "a[0] = x[indexes0]*w # x[indexes0] is ([1, 2, 3])\\\n",
        "a[1] = x[indexes1]*w # x[indexes1] is ([2, 3, 4])\\\n",
        "a = a.sum(axis=1)\\\n",
        "The ndarray method takes advantage of the fact that it is possible to specify indexes using arrays.\n",
        "\n",
        "You can also use ndarray to get a two-dimensional array out of a one-dimensional array.\n",
        "\n",
        "x = np.array([1, 2, 3, 4])\\\n",
        "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\\\n",
        "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])\\\n",
        "With a good combination of this and a broadcast or similar, it is possible to compute them all at once.\n",
        "\n",
        "There is no right answer to the calculation method of convolution, so you can make it more efficient in your own way.\n",
        "\n",
        "Reference\n",
        "\n",
        "The Integer array indexing section of the following page is a description of this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2bueBhvKaSf",
        "outputId": "440ed799-b2ba-48f6-c99e-42103ff5a11d"
      },
      "source": [
        "# Samples\n",
        "x = np.array([1, 2, 3, 4])\n",
        "y = np.array([45,70])\n",
        "w = np.array([3, 5, 7])\n",
        "a = np.empty((2, 3))\n",
        "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
        "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
        "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
        "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
        "a = a.sum(axis=1)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([34., 49.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj5N_ZTgKEG3"
      },
      "source": [
        "###[Answer.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvq8r90PKmpF"
      },
      "source": [
        "def Forward(X, W, B=1, P=0, S=1):\n",
        "    \n",
        "    lenX = X.shape[0]\n",
        "    lenW = W.shape[0]\n",
        "    \n",
        "    Nout = lenX - lenW +1\n",
        "\n",
        "    index_list = np.zeros((Nout, lenW)).astype(np.int)\n",
        "\n",
        "    for i in range(Nout):\n",
        "        index_list[i] = (np.arange(i, lenW + i ))\n",
        "\n",
        "    output = np.dot(X[index_list], W) + B\n",
        "    \n",
        "    return output\n",
        "\n",
        "def cross_entropy_loss(pred, label):\n",
        "    return label - pred\n",
        "    \n",
        "def backward(lr, X, W, loss):\n",
        "    lenX = X.shape[0]\n",
        "    lenW = W.shape[0]\n",
        "    \n",
        "    Nout = lenX - lenW +1\n",
        "\n",
        "    index_list = np.zeros((Nout, lenW)).astype(np.int)\n",
        "\n",
        "    for i in range(Nout):\n",
        "        index_list[i] = (np.arange(i, lenW + i ))\n",
        "        \n",
        "        \n",
        "    dB = np.sum(loss)\n",
        "    dW = np.dot(loss, X[index_list])\n",
        "\n",
        "    dX = np.zeros((lenX,))\n",
        "    for i,index in enumerate(index_list):\n",
        "        dX[index] += loss[i] * W\n",
        "        print(dX)\n",
        "                \n",
        "            \n",
        "    #print(dX)\n",
        "    return dW, dB, dX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDvLl3Y8Kr-T",
        "outputId": "b61372cc-85b0-4c92-deba-c91471bed26c"
      },
      "source": [
        "pred = Forward(x,w)\n",
        "loss = cross_entropy_loss(pred, y)\n",
        "dW, dB, dX = backward(0.01,x,w,loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30. 50. 70.  0.]\n",
            "[ 30. 110. 170. 140.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0OHD6dNKxCD",
        "outputId": "8ea24dc3-6b5f-432a-82f8-0ca663bc4a65"
      },
      "source": [
        "print(\"forward_result : {}\".format(pred))\n",
        "print(\"loss : {}\".format(loss))\n",
        "print(\"backward_result\")\n",
        "print(\"delta_b : {}\".format(dB))\n",
        "print(\"delta_w : {}\".format(dW))\n",
        "print(\"delta_x : {}\".format(dX))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_result : [35 50]\n",
            "loss : [10 20]\n",
            "backward_result\n",
            "delta_b : 30\n",
            "delta_w : [ 50  80 110]\n",
            "delta_x : [ 30. 110. 170. 140.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fUb9SnOK3l-"
      },
      "source": [
        "# [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0NwFcWnLHul"
      },
      "source": [
        "xx = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)and (number of input channels, number of features).\n",
        "ww = np.ones((3, 2, 3)) # All are set to 1 to simplify the example. (number of output channels, number of input channels, filter size).\n",
        "bb = np.array([1, 2, 3]) # (number of output channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFyf8lQLJqb"
      },
      "source": [
        "#xx = np.array([[1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6]]) # shape(2, 4), with (number of input channels, number of features).\n",
        "#ww = np.ones((4, 3, 3)) # all 1 for simplicity of the example. (number of output channels, number of input channels, filter size).\n",
        "#bb = np.array([1, 2, 3,4]) # (number of output channels)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYLG8ZZLOgd"
      },
      "source": [
        "class CNN1d:\n",
        "    def __init__(self,W, B, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.B = B\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "    def forward(self, X):\n",
        "        print(X.shape)\n",
        "        self.FN, self.C, self.FS = self.W.shape \n",
        "        self.C, self.S = X.shape\n",
        "        #print(self.F, self.FS)\n",
        "        self.Nout = int(((self.S + 2*self.pad - self.FS) / self.stride) + 1)\n",
        "        #print(X)\n",
        "        #print(self.FN)\n",
        "        \n",
        "        # Dimensionality reduction of W　W(FN,C,FS) →W(FNC,FS)\n",
        "        self.reW= self.W.reshape(self.FN,-1).T\n",
        "        print(self.reW)\n",
        "        print(\"reWのshape:\\n{}\".format(self.reW.shape))\n",
        "        \n",
        "        # Create an output empty output.shape=(4,2) ※(S, Nout)\n",
        "        self.output = np.zeros((self.S,self.Nout))\n",
        "\n",
        "        #An empty array to expand X openX.shape=(2,6)\n",
        "        self.openX = np.zeros((self.Nout,self.FN*self.C))\n",
        "        \n",
        "        # An empty array to store the index shape=(2,3)\n",
        "        self.index_list = np.zeros((self.Nout, self.FN)).astype(np.int)\n",
        "        # We'll put the index number into that array.\n",
        "        for i in range(self.Nout):\n",
        "            self.index_list[i] = np.arange(i, self.FN + i )\n",
        "        \n",
        "        #ss = np.arange\n",
        "        \n",
        "        #This time, we create an array called [[0,1,2],[1,2,3]]\n",
        "                \n",
        "        #print(\"Empty array for output:\\n{}\\n\".format(self.output))\n",
        "        #print(\"Preparing X expansion:\\n{}\\n\".format(self.openX)) \n",
        "        print(\"test\")\n",
        "        print(self.openX[:,self.index_list[0]])\n",
        "        print(X[0])\n",
        "        \n",
        "        # enumerate the list of indices and X\n",
        "        #utilize each index to store the contents of X in openX\n",
        "        for k,v in enumerate(self.index_list):\n",
        "            for k2,v2 in enumerate(X):\n",
        "                #print(k,v,k2,v2)\n",
        "                if k2 == 0:\n",
        "                    self.openX[k][v - k] = v2[v]\n",
        "                elif k2 == 1:\n",
        "                    self.openX[k][v + len(v) - k] = v2[v]\n",
        "                else:\n",
        "                    self.openX[k][v + len(v)*k2 - k] = v2[v]\n",
        "                \n",
        "        print(self.openX)\n",
        "        \n",
        "        \n",
        "        # Add B to the dot product of the expanded X and W.\n",
        "        # (2,6) @ (6, 3) + (3,) = (2,3)\n",
        "        self.output = np.dot(self.openX, self.reW) + self.B\n",
        "\n",
        "        #print(\"Filtered index:\\n{}\\n\".format(self.index_list))\n",
        "        #print(\"Expand W into a two-dimensional array:\\n{}\\n\".format(self.reW))        \n",
        "         \n",
        "        #print(\"X into a two-dimensional array:\\n{}\\n\".format(self.openX))\n",
        "        #print(\"Output of forward:\\n{}\\n\".format(self.output.T))\n",
        "        \n",
        "        # output transposed at the end shape=(3,2)\n",
        "        return self.output.T\n",
        "    \n",
        "    \n",
        "    def cross_entropy_loss(self, pred, label):\n",
        "        #print(\"y:\\n{}\\n\".format(label))\n",
        "        return label - pred\n",
        "\n",
        "    def backward(self, X, W, loss):\n",
        "\n",
        "        # delta_B sums up the loss\n",
        "        dB = np.sum(loss)\n",
        "        #print(\"dB:\\n{}\\n\".format(dB))\n",
        "        \n",
        "        # delta_W is the dot product of loss and X (where X is the expansion of the previous forward), reshape to the form W\n",
        "        dW = np.dot(loss,self.openX).reshape(self.W.shape)\n",
        "        #print(\"dW:\\n{}\\n\".format(dW))\n",
        "        \n",
        "        # empty array to store delta_X dX.shape=(2,4)\n",
        "        dX = np.zeros(X.shape)\n",
        "        #print(dX)\n",
        "\n",
        "        # Calculate the contents to be stored in delta_X.\n",
        "        # dot product of W.T and loss (3,2,3) @ (3,2) = (3,2,2) transpose to (2,2,3)\n",
        "        calc = np.dot(self.W.T, loss).T\n",
        "        #print(calc)\n",
        "        #print(calc)\n",
        "        \n",
        "        for k,v in enumerate(self.index_list):\n",
        "            dX[:,v] += calc[k]\n",
        "\n",
        "\n",
        "\n",
        "        #print(dX)\n",
        "        return dW, dB, dX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfqZiVRsLwLR",
        "outputId": "292408ab-8e55-4fed-9540-9d83aa76c8ac"
      },
      "source": [
        "trap = CNN1d(ww,bb)\n",
        "dA = trap.forward(xx)\n",
        "#loss = trap.cross_entropy_loss(pred, yy)\n",
        "print(dA)\n",
        "dW, dB, dX = trap.backward(xx,ww,dA)\n",
        "dW, dB, dX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 4)\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "reWのshape:\n",
            "(6, 3)\n",
            "test\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[1 2 3 4]\n",
            "[[1. 2. 3. 2. 3. 4.]\n",
            " [2. 3. 4. 3. 4. 5.]]\n",
            "[[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 60.,  98., 136.],\n",
              "         [ 98., 136., 174.]],\n",
              " \n",
              "        [[ 63., 103., 143.],\n",
              "         [103., 143., 183.]],\n",
              " \n",
              "        [[ 66., 108., 150.],\n",
              "         [108., 150., 192.]]]), 120.0, array([[ 51., 120., 120.,  69.],\n",
              "        [ 51., 120., 120.,  69.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3epTTgc8L0Vp"
      },
      "source": [
        "# [Problem 5] (Advanced task) Implementing padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0l_T8ihMBRx"
      },
      "source": [
        "# permutation\n",
        "def _padding(X, n):\n",
        "    return np.pad(X, [(0,0), (n,n), (n,n)]) # [(cb,ca), (hu,hd), (wl,wr)].\n",
        "\n",
        "# For back propagation\n",
        "def _padding_rm(X, n):\n",
        "    return X[:, n:-n, n:-n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaBWmeFxMDZu",
        "outputId": "73753b21-cecf-484e-cff7-02c71fd1a54a"
      },
      "source": [
        "X = np.arange(30).reshape(1,6,5)\n",
        "n = 3\n",
        "\n",
        "print(X)\n",
        "X_ = _padding(X, n)\n",
        "print(X_)\n",
        "X_ = _padding_rm(X_, n)\n",
        "print(X_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]\n",
            "  [15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n",
            "[[[ 0  0  0  0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  2  3  4  0  0  0]\n",
            "  [ 0  0  0  5  6  7  8  9  0  0  0]\n",
            "  [ 0  0  0 10 11 12 13 14  0  0  0]\n",
            "  [ 0  0  0 15 16 17 18 19  0  0  0]\n",
            "  [ 0  0  0 20 21 22 23 24  0  0  0]\n",
            "  [ 0  0  0 25 26 27 28 29  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0]]]\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]\n",
            "  [15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5_63v5MG-p"
      },
      "source": [
        "# [Problem 6] (Advanced task) Response to mini batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgvhHAXFMKoE"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to retrieve the mini-batch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of the following form, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : ndarray of the following form, shape (n_samples, 1)\n",
        "      The correct answer value\n",
        "    batch_size : int\n",
        "      batch size\n",
        "    seed : int\n",
        "      Seed of random number in NumPy\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y-Zvr5MMNlX"
      },
      "source": [
        "# Functions in the Conv1d class\n",
        "def _convolve(X, k, P, S):\n",
        "    \"\"\"\n",
        "    Cyclic operation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of the following form, shape (N, C, L)\n",
        "      the matrix to be traversed\n",
        "    k : ndarray of the following form, shape (F, C, Lf)\n",
        "      the matrix to be traversed\n",
        "    \"\"\"\n",
        "    L = X.shape[-1]\n",
        "    Lf = k.shape[-1]\n",
        "    Lo = self._output_size(L, Lf, P, S) \n",
        "\n",
        "    # Generate w for Teplitz\n",
        "    pad = int(L - Lf) # adjust the length of k to X\n",
        "    k_pad = np.pad(k, [(0,0), (0,0), (0, pad)]) # k(F,C,Lf) → k(F,C,L)\n",
        "    # Dimensionality reduction\n",
        "    X_flat = X.reshape(len(X), -1) # X(N,C,L) → X(N,CL)\n",
        "    k_flat = k_pad.flatten() # k(F,C,L) → k(FCL)\n",
        "    # generate the Teplitz matrix\n",
        "    first_col = np.r_[k_flat[0], np.zeros(S * (Lo-1))] # first column of Teplitz\n",
        "    first_row = k_flat # first row of Teplitz  \n",
        "    toep = linalg.toeplitz(first_col, first_row) # toep(Lo,FLC)\n",
        "    # Get only the row corresponding to the stride\n",
        "    toep_ = toep[::S]\n",
        "    # Block the matrix for each filter and recombine vertically\n",
        "    toep_reorder = np.vstack(np.split(toep_, len(k), axis=1)) #toep(FLo,LC)\n",
        "    # matrix operation\n",
        "    output = toep_reorder@X_flat.T  # out(FLo,N)\n",
        "\n",
        "    return output.T.reshape(len(X), len(k), Lo)  # out(N,F,Lo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY5d1p20MRJS"
      },
      "source": [
        "# [Problem 7] (Advance assignment) Arbitrary number of strides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksWOUTyiMUUf"
      },
      "source": [
        "def convolve(X, k, P, S):\n",
        "    L = X.shape[-1]\n",
        "    Lf = k.shape[-1]\n",
        "    Lo = int((L + 2*P - Lf) / S + 1)\n",
        "\n",
        "    # Generate w for Teplitz\n",
        "    pad = int(L - Lf) # adjust the length of k to X\n",
        "    k_pad = np.pad(k, [(0,0), (0,0), (0, pad)]) # k(F,C,Lf) → k(F,C,L)\n",
        "    # Dimensionality reduction\n",
        "    X_flat = X.reshape(len(X), -1) # X(N,C,L) → X(N,CL)\n",
        "    k_flat = k_pad.flatten() # k(F,C,L) → k(FCL)\n",
        "    # generate the Teplitz matrix\n",
        "    first_col = np.r_[k_flat[0], np.zeros(S*(Lo-1))] # first column of Teplitz\n",
        "    first_row = k_flat # first row of Teplitz  \n",
        "    toep = linalg.toeplitz(first_col, first_row) # toep(Lo,FLC)\n",
        "    # Get only the row corresponding to the stride\n",
        "    toep = toep[::S] \n",
        "    # Block the matrix for each filter and recombine vertically\n",
        "    toep_reorder = np.vstack(np.split(toep, len(k), axis=1)) #toep(FLo,LC)\n",
        "    # matrix operation\n",
        "    output = toep_reorder@X_flat.T  # out(FLo,N)\n",
        "    \n",
        "    return output.T.reshape(len(X), len(k), Lo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Uzw254hkMWsc",
        "outputId": "f742de27-37dd-4890-d1ac-853334cb61a2"
      },
      "source": [
        "# Example: Forward propagation (S=2)\n",
        "\n",
        "X = np.arange(6).reshape(1,1,6) # N,C,L\n",
        "w = np.arange(2).reshape(1,1,2) # F,C,Lf\n",
        "S = 2\n",
        "P = 0\n",
        "print(X)\n",
        "print(w)\n",
        "print(S)\n",
        "print(P)\n",
        "\n",
        "Z = convolve(X, w, P, S)\n",
        "print(Z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 1 2 3 4 5]]]\n",
            "[[[0 1]]]\n",
            "2\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-6ebfac68ed08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-158868ae2558>\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(X, k, P, S)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfirst_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLo\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# first column of Teplitz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfirst_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_flat\u001b[0m \u001b[0;31m# first row of Teplitz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtoep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoeplitz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_row\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# toep(Lo,FLC)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Get only the row corresponding to the stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtoep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linalg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avBVU-TRMZP0"
      },
      "source": [
        "# Example: Back propagation (S=2)\n",
        "dA = Z\n",
        "Z = X\n",
        "\n",
        "# dZ calculation\n",
        "# transpose the matrix to perform the operation on each channel (leaving N and C)\n",
        "w_ = np.transpose(w, (1,0,2)) # w(F,C,Lf) → w(C,F,Lf)\n",
        "w_ = np.flip(w_) # flip up/down/left/right\n",
        "# dilate dA\n",
        "N, F, Lo = dA.shape\n",
        "dA_dil = np.zeros((N, F, S*Lo-S+1)) # prepare dilation matrix\n",
        "dA_dil[... ,::S] = dA\n",
        "# padding dA_dil\n",
        "pad = w.shape[-1] - 1\n",
        "dA_pad = np.pad(dA_dil, [(0,0), (0,0), (pad, pad)]) # padding only L dimension\n",
        "# cyclic operation\n",
        "dZ_ = convolve(dA_pad, w_, 0, 1) # dZ(N,C,L)\n",
        "\n",
        "\n",
        "# dw calculation            \n",
        "# transpose the matrices (leaving F and C) to perform the operation on each filter\n",
        "Z_ = np.transpose(Z, (1,0,2))  # Z(N,C,L) → Z(C,N,L)\n",
        "dA_ = np.transpose(dA_dil, (1,0,2))  # dA(N,F,Lo) → dA(F,N,Lo)\n",
        "dw_ = np.transpose(convolve(Z_, dA_, 0, 1), (1,0,2))  # dw(C,F,Lf) → dw(F,C,Lf)\n",
        "\n",
        "print(dw_)\n",
        "print(dZ_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0OPvV2BMgHQ"
      },
      "source": [
        "# [Problem 8] Learning and estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dnnq5hAMrL9"
      },
      "source": [
        "import time\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def update_dw(self, layer, grad):\n",
        "        return grad / layer.input.shape[0]\n",
        "    \n",
        "    def update_db(self, layer, grad):\n",
        "        return grad / layer.input.shape[0]\n",
        "        \n",
        "\n",
        "class AdaGrad:\n",
        "    def __init__(self):\n",
        "        self.Hw = 1e-8\n",
        "        self.Hb = 1e-8\n",
        "        \n",
        "    def update_dw(self, layer, grad):\n",
        "        self.Hw += (grad/layer.input.shape[0])**2\n",
        "        grad *= (1/np.sqrt(self.Hw)) / layer.input.shape[0]\n",
        "        \n",
        "        return grad\n",
        "    \n",
        "    def update_db(self, layer, grad):\n",
        "        self.Hb += (grad/layer.input.shape[0])**2\n",
        "        grad *= (1/np.sqrt(self.Hb)) / layer.input.shape[0]\n",
        "        \n",
        "        return grad\n",
        "        \n",
        "        \n",
        "class Conv1d:\n",
        "    def __init__(self, pad='SAME', stride=1):\n",
        "        self.pad = pad\n",
        "        self.stride = stride\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        # Define various shapes and parameters\n",
        "        L = Z.shape[-1]\n",
        "        Lf = w.shape[-1]\n",
        "        S = self.stride\n",
        "        \n",
        "        # Padding process\n",
        "        if self.pad == 'SAME':\n",
        "            if L % S == 0:\n",
        "                P = int((Lf - S) / 2)\n",
        "            else:\n",
        "                P = int((Lf - L%S) / 2)\n",
        "            Z = self._padding(Z, P)\n",
        "        elif self.pad == 'VALID':\n",
        "            P = 0\n",
        "        self.P = P\n",
        "        \n",
        "        self.A_ = self._convolve(Z, w, P, S) + b.reshape(1, len(b), 1)  # A(N,F,Lo)\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        S = self.stride\n",
        "        \n",
        "        # dZ calculation\n",
        "        # transpose the matrix (leaving N and C) to perform the operation on each channel\n",
        "        w_ = np.transpose(w, (1,0,2)) # w(F,C,Lf) → w(C,F,Lf)\n",
        "        w_ = np.flip(w_) # flip up/down/left/right\n",
        "        # dilate dA\n",
        "        N, F, Lo = dA.shape\n",
        "        dA_dil = np.zeros((N, F, S*Lo-S+1)) # prepare dilation matrix\n",
        "        dA_dil[... ,::S] = dA\n",
        "        # padding dA_dil\n",
        "        pad = w.shape[-1] - 1\n",
        "        dA_pad = np.pad(dA_dil, [(0,0), (0,0), (pad, pad)]) # padding only L dimension\n",
        "        # Cyclic operation\n",
        "        dZ_ = self._convolve(dA_pad, w_, 0, 1) # dZ(N,C,L)\n",
        "        # Padding removal\n",
        "        if self.P == 0:\n",
        "            self.dZ_ = dZ_\n",
        "        else:\n",
        "            self.dZ_ = self._padding_rm(dZ_, self.P)\n",
        "        \n",
        "        # dw calculation            \n",
        "        # transpose the matrices to perform the operation on each filter (leaving F and C)\n",
        "        Z_ = np.transpose(Z, (1,0,2)) # Z(N,C,L) → Z(C,N,L)\n",
        "        dA_ = np.transpose(dA_dil, (1,0,2)) # dA(N,F,Lo) → dA(F,N,Lo)\n",
        "        self.dw_ = np.transpose(self._convolve(Z_, dA_, self.P, 1), (1,0,2)) # dw(C,F,Lf) → dw(F,C,Lf)\n",
        "        \n",
        "        # db calculation \n",
        "        # sum over all dimensions except F\n",
        "        self.db_ = np.sum(dA, axis=(0,2)) # db(F)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "    \n",
        "    def _output_size(self, L, Lf, P, S):\n",
        "        Lo = (L + 2*P - Lf) / S + 1   \n",
        "        return int(Lo)\n",
        "    \n",
        "    def _padding(self, X, n):\n",
        "        # for forward propagation\n",
        "        return np.pad(X, [(0,0), (0,0), (n,n)])\n",
        "\n",
        "    def _padding_rm(self, X, n):\n",
        "        # for back propagation\n",
        "        return X[... , n:-n]\n",
        "    \n",
        "    def _convolve(self, X, k, P, S):\n",
        "        L = X.shape[-1].\n",
        "        Lf = k.shape[-1].\n",
        "        Lo = self._output_size(L, Lf, P, S) \n",
        "\n",
        "        # Generate w for Teplitz\n",
        "        pad = int(L - Lf) # adjust the length of k to X\n",
        "        k_pad = np.pad(k, [(0,0), (0,0), (0, pad)]) # k(F,C,Lf) → k(F,C,L)\n",
        "        # Dimensionality reduction\n",
        "        X_flat = X.reshape(len(X), -1) # X(N,C,L) → X(N,CL)\n",
        "        k_flat = k_pad.flatten() # k(F,C,L) → k(FCL)\n",
        "        # generate the Teplitz matrix\n",
        "        first_col = np.r_[k_flat[0], np.zeros(S * (Lo-1))] # first column of Teplitz\n",
        "        first_row = k_flat # first row of Teplitz  \n",
        "        toep = linalg.toeplitz(first_col, first_row) # toep(Lo,FLC)\n",
        "        # Get only the row corresponding to the stride\n",
        "        toep = toep[::S]. \n",
        "        # Block the matrix for each filter and recombine vertically\n",
        "        toep_reorder = np.vstack(np.split(toep, len(k), axis=1)) #toep(FLo,LC)\n",
        "        # matrix operation\n",
        "        output = toep_reorder@X_flat.T  # out(FLo,N)\n",
        "\n",
        "        return output.T.reshape(len(X), len(k), Lo)  # out(N,F,Lo)\n",
        "    \n",
        "\n",
        "class Linear:\n",
        "    def __init__(self):\n",
        "        self.A_ = None\n",
        "        self.dZ_ = None\n",
        "        self.dw_ = None\n",
        "        self.db_ = None\n",
        "        \n",
        "    def forward(self, Z, w, b):\n",
        "        self.A_ = Z @ w + b\n",
        "        \n",
        "        return self.A_\n",
        "    \n",
        "    def backward(self, Z, w, dA):\n",
        "        self.dZ_ = dA @ w.T\n",
        "        self.dw_ = Z.T @ dA\n",
        "        self.db_ = np.sum(dA, axis=0)\n",
        "        \n",
        "        return self.dZ_, self.dw_, self.db_\n",
        "\n",
        "        \n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        self.Z_ = 1 / (1+np.exp(-A))\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        self.dA_ = dZ * ((1 - self.Z_) * self.Z_)\n",
        "    \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        self.Z_ = np.tanh(A)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        self.dA_ = dZ * (1 - self.Z_**2)\n",
        "        \n",
        "        return self.dA_\n",
        "        \n",
        "        \n",
        "class ReLu:\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        self.Z_ = np.maximum(A, 0)\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        self.dA_ = dZ * np.where(self.Z_ > 0, 1, 0)\n",
        "        \n",
        "        return self.dA_\n",
        "    \n",
        "        \n",
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        self.Z_ = None\n",
        "        self.dA_ = None\n",
        "        \n",
        "    def forward(self, A):\n",
        "        # Subtraction of constants to prevent overflow\n",
        "        C = np.max(A)\n",
        "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
        "        \n",
        "        return self.Z_\n",
        "    \n",
        "    def backward(self, y):\n",
        "        self.dA_ = self.Z_ - y\n",
        "        \n",
        "        return self.dA_\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.shape = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(self.shape[0], np.prod(self.shape[1:]))  # X(N,C,L) → X(N,CL)\n",
        "    \n",
        "    def backward(self, dX):\n",
        "        return dX.reshape(self.shape)\n",
        "                    \n",
        "        \n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, shape_self):\n",
        "        W = self.sigma * np.random.standard_normal(shape_self)\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        B = np.random.randn(n_nodes_self)\n",
        "        return B\n",
        "    \n",
        "\n",
        "class XavierInitializer:\n",
        "    def __init__(self):\n",
        "        self.sigma = None\n",
        "    \n",
        "    def W(self, n_nodes_prev, shape_self):\n",
        "        self.sigma = 1 / np.sqrt(np.prod(n_nodes_prev))\n",
        "        \n",
        "        W = self.sigma * np.random.standard_normal(shape_self)  # Use standard_normal which can take a tuple as an argument\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        B = np.random.standard_normal(shape_self)\n",
        "        return B\n",
        "    \n",
        "    \n",
        "class HeInitializer:\n",
        "    def __init__(self):\n",
        "        self.sigma = None\n",
        "        \n",
        "    def W(self, n_nodes_prev, shape_self):\n",
        "        self.sigma = np.sqrt(2/np.prod(n_nodes_prev))\n",
        "        \n",
        "        W = self.sigma * np.random.standard_normal(shape_self)  # Use standard_normal which can take a tuple as an argument\n",
        "        return W\n",
        "    \n",
        "    def B(self, shape_self):\n",
        "        B = np.random.standard_normal(shape_self)\n",
        "        return B\n",
        "    \n",
        "    \n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to retrieve the mini-batch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of the following form, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : ndarray of the following form, shape (n_samples, 1)\n",
        "      The correct answer value\n",
        "    batch_size : int\n",
        "      batch size\n",
        "    seed : int\n",
        "      Seed of random number in NumPy\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "            def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "    \n",
        "    \n",
        "class Layer:\n",
        "    def __init__(self, combination, activation, \n",
        "                 initializer=None, optimizer=None, n_nodes_prev=None, w_shape=None, b_shape=None):\n",
        "        self.comb = combination\n",
        "        self.activ = activation\n",
        "        self.initializer = initializer # Use the initializer method to initialize self.W and self.B\n",
        "        self.optimizer = optimizer\n",
        "        self.n_nodes_prev = n_nodes_prev\n",
        "        self.w_shape = w_shape\n",
        "        self.b_shape = b_shape\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        self.prev = None\n",
        "        self.next = None\n",
        "        \n",
        "        if self.initializer:\n",
        "            self.w = self.initializer.W(self.n_nodes_prev, self.w_shape)\n",
        "            self.b = self.initializer.B(self.b_shape)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        if self.comb:\n",
        "            A = self.comb.forward(X, self.w, self.b)\n",
        "            Z = self.activ.forward(A)\n",
        "\n",
        "        else:\n",
        "            Z = self.activ.forward(X)\n",
        "        \n",
        "        self.input = X\n",
        "        self.output = Z\n",
        "        \n",
        "        if self.next:\n",
        "            return self.next.forward(Z)\n",
        "        else:\n",
        "            return Z\n",
        "    \n",
        "    def backward(self, y, lr):\n",
        "        if self.comb:\n",
        "            dA = self.activ.backward(y)\n",
        "            dZ, dw, db = self.comb.backward(self.input, self.w, dA)\n",
        "            \n",
        "            # Parameter update\n",
        "            self.w -= lr * self.optimizer.update_dw(self, dw)\n",
        "            self.b -= lr * self.optimizer.update_db(self, db)\n",
        "            \n",
        "        else:\n",
        "            dZ = self.activ.backward(y)\n",
        "        \n",
        "        if self.prev:\n",
        "            self.prev.backward(dZ, lr)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    \n",
        "class Scratch1dCNNClassifier:\n",
        "    def __init__(self, layers, epoch=100, sigma=0.1, lr=0.01, batch_size=100, verbose=False, **kwargs):\n",
        "        self.layers = layers\n",
        "        self.epoch = epoch\n",
        "        self.lr = lr\n",
        "        self.sigma = sigma\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "\n",
        "    def _connect_layers(self, layers):\n",
        "        for i, layer in enumerate(layers): \n",
        "            \n",
        "            if i == 0:\n",
        "                layer.next = self.layers[i+1]\n",
        "                \n",
        "            elif layer == self.layers[-1]:\n",
        "                layer.prev = self.layers[i-1]\n",
        "                \n",
        "            else:\n",
        "                layer.next = self.layers[i+1]\n",
        "                layer.prev = self.layers[i-1]\n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        # Create a layer instance\n",
        "        self._connect_layers(self.layers)    \n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            \n",
        "            get_mini_batch_t = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            \n",
        "            times = []\n",
        "            start = time.time()\n",
        "            \n",
        "            # List of losses for each mini batch\n",
        "            loss_batch_t = []\n",
        "            \n",
        "            for X_mini, y_mini in get_mini_batch_t:\n",
        "\n",
        "                # Forward propagation\n",
        "                output = self.layers[0].forward(X_mini)\n",
        "                # Back propagation\n",
        "                self.layers[-1].backward(y_mini, self.lr)\n",
        "\n",
        "                loss_batch_t.append(self.cross_entropy(output, y_mini))\n",
        "            \n",
        "            # Store the average loss for each epoch in self\n",
        "            loss_train = np.mean(loss_batch_t)\n",
        "            self.loss_train.append(loss_train)\n",
        "            \n",
        "            \n",
        "            # Estimation of validation data\n",
        "            if hasattr(X_val, '__array__') and hasattr(y_val, '__array__'):\n",
        "                \n",
        "                batch_size_v = int(self.batch_size * len(X_val)/len(X))\n",
        "                get_mini_batch_v = GetMiniBatch(X_val, y_val, batch_size=batch_size_v)\n",
        "                loss_batch_v = []\n",
        "\n",
        "                for X_mini, y_mini in get_mini_batch_v:\n",
        "                    \n",
        "                    output = self.layers[0].forward(X_mini)\n",
        "                \n",
        "                    loss_batch_v.append(self.cross_entropy(output, y_mini))\n",
        "            \n",
        "                # Store the average loss for each epoch in self\n",
        "                loss_val = np.mean(loss_batch_v)\n",
        "                self.loss_val.append(loss_val)\n",
        "\n",
        "            end = time.time()\n",
        "            times.append(end-start)\n",
        "\n",
        "            # Output of learning progress\n",
        "            if self.verbose:\n",
        "                print(\"Epoch {}: Train Loss {:.4f}, Val Loss {:.4f}\".format(i+1, loss_train, loss_val),\n",
        "                      \" --{:.4f}sec\".format(np.mean(times)))            \n",
        "                   \n",
        "    def predict(self, X):\n",
        "        output = self.layers[0].forward(X)\n",
        "        \n",
        "        return np.argmax(output, axis=1)\n",
        "        \n",
        "    def cross_entropy(self, X, y):\n",
        "        return (-1/len(X)) * np.sum((y*np.log(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FTVH8ZWNb6s"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Code to download the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Smoothing data\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "# Standardise on X\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "# ytoone-hot encode\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "# Converting features to 3D\n",
        "X_train = X_train[:, None, :]\n",
        "X_val = X_val[:, None, :]\n",
        "X_test = X_test[:, None, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XfZvFo-NpCm"
      },
      "source": [
        "def plot_loss(model, title='Scratch CNN Loss'):\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(np.arange(len(model.loss_train)), model.loss_train, label='train loss')\n",
        "    plt.plot(np.arange(len(model.loss_val)), model.loss_val, label='val loss')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqGZ9COHNjNY"
      },
      "source": [
        "# Setting of hyperparameters w(F,C,Lf) b(F)\n",
        "W1 = np.array((4,1,6)); B1 = 4\n",
        "W2 = np.array((8,4,6)); B2 = 8\n",
        "W3 = np.array((16,8,3)); B3 = 16\n",
        "W4 = np.array((752,188)); B4 = 188\n",
        "W5 = np.array((188,10)); B5 = 10\n",
        "\n",
        "# 5-layer network\n",
        "layer_1 = Layer(Conv1d(pad='SAME', stride=4), ReLu(), HeInitializer(), AdaGrad(), 784, W1, B1)  # 1,784 to 4,196\n",
        "layer_2 = Layer(Conv1d(pad='SAME', stride=4), ReLu(), HeInitializer(), AdaGrad(), 4*196, W2, B2)  # 4,196 to 8,49\n",
        "layer_3 = Layer(Conv1d(pad='VALID', stride=1), ReLu(), HeInitializer(), AdaGrad(), 8*49, W3, B3)  # 8,49 to 16,47\n",
        "layer_4 = Layer(None, Flatten())  # 16,47 to 752,\n",
        "layer_5 = Layer(Linear(), Sigmoid(), XavierInitializer(), AdaGrad(), 752, W4, B4)  # 752, to 188,\n",
        "output = Layer(Linear(), Softmax(), XavierInitializer(), AdaGrad(), 188, W5, B5)  # 188, to 10,\n",
        "\n",
        "params = {'epoch': 10, \n",
        "          'lr': 0.01,\n",
        "          'batch_size': 200,\n",
        "          }\n",
        "\n",
        "cnn = Scratch1dCNNClassifier(layers=[layer_1, layer_2, layer_3, layer_4, layer_5, output],\n",
        "                             verbose=True, **params)\n",
        "\n",
        "cnn.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "pred = cnn.predict(X_test)\n",
        "\n",
        "print(\"\\nTest Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
        "\n",
        "plot_loss(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOvawUT7Nuna"
      },
      "source": [
        "# Check estimation results\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(20):\n",
        "    pred = cnn.predict(X_test[i][None,...])\n",
        "    true = y_test[i]\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28,28), 'gray')\n",
        "    plt.title('pred {} \\ntrue [{}]'.format(pred, true), y=-0.45)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}